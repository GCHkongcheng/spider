# 智能通用新闻爬虫系统

## 项目简介

这是一个智能的通用新闻爬虫系统，支持多个主流新闻网站的新闻爬取，具备自动网站检测和选择功能。系统会智能判断网站的可访问性和内容结构，自动选择最适合的新闻源进行爬取。

## 功能特点

- ✅ **多网站支持**: 支持网易财经、新浪财经、腾讯财经、央视网财经、人民网财经等多个新闻网站
- ✅ **智能检测**: 自动检测网站可用性和内容结构有效性
- ✅ **自动选择**: 智能推荐最佳可用的新闻网站
- ✅ **用户友好**: 提供交互式界面，用户可手动选择新闻源
- ✅ **多格式保存**: 支持 JSON、CSV、Excel 等多种数据保存格式
- ✅ **智能反爬**: 随机 User-Agent、请求间隔等反爬虫策略
- ✅ **完整日志**: 详细的爬取过程日志记录
- ✅ **错误处理**: 完善的错误处理和重试机制
- ✅ **数据统计**: 自动生成爬取数据的统计摘要

## 支持的新闻网站

| 网站名称   | 网址                          | 状态    |
| ---------- | ----------------------------- | ------- |
| 网易财经   | https://money.163.com/        | ✅ 支持 |
| 新浪财经   | https://finance.sina.com.cn/  | ✅ 支持 |
| 腾讯财经   | https://finance.qq.com/       | ✅ 支持 |
| 央视网财经 | http://finance.cctv.com/      | ✅ 支持 |
| 人民网财经 | http://finance.people.com.cn/ | ✅ 支持 |

## 项目结构

```
za/
├── crawler/                     # 爬虫核心模块
│   ├── __init__.py             # 包初始化
│   ├── main.py                 # 主程序入口
│   ├── universal_spider.py     # 通用爬虫类
│   ├── site_detector.py        # 网站检测器
│   ├── data_manager.py         # 数据管理类
│   ├── config.py               # 配置文件
│   ├── utils.py                # 工具函数
│   └── spider.py               # 向后兼容的原爬虫类
├── data/                       # 数据存储目录
│   ├── spider.log              # 爬虫日志
│   ├── *.json                  # JSON格式数据
│   ├── *.csv                   # CSV格式数据
│   └── *.xlsx                  # Excel格式数据
├── requirements.txt            # 依赖包列表
├── run.py                      # 快速运行脚本
├── test.py                     # 测试脚本
└── README.md                   # 项目说明
```

## 环境要求

- Python 3.7+
- 相关依赖包（见 requirements.txt）

## 安装步骤

1. 克隆或下载项目到本地

2. 安装依赖包：

```bash
pip install -r requirements.txt
```

## 如何运行项目

### 快速开始

1. **运行测试验证系统**（推荐先运行）：

```bash
cd "d:\Code\Py\za"
.\.venv\Scripts\python.exe test_new.py
```

2. **运行完整的爬虫程序**：

```bash
# 方法一：使用快速运行脚本
.\.venv\Scripts\python.exe run.py

# 方法二：直接运行主程序
.\.venv\Scripts\python.exe crawler\main.py
```

### 运行流程

1. **启动程序**：系统显示欢迎横幅
2. **网站检测**：自动检测所有配置的新闻网站可用性
3. **用户选择**：
   - 选择 `0` - 自动选择最佳可用网站
   - 选择 `1-N` - 手动选择特定网站
4. **开始爬取**：系统开始爬取选定网站的新闻
5. **数据保存**：自动保存为 JSON、CSV、Excel 三种格式
6. **结果展示**：显示爬取统计和新闻预览

### 程序特色

✨ **智能检测**：自动检测网站连通性和内容结构
✨ **用户友好**：提供清晰的选择界面和进度提示
✨ **多网站支持**：支持 5 个主流财经新闻网站
✨ **数据完整**：提供详细的统计信息和数据预览
✨ **格式多样**：同时保存 JSON、CSV、Excel 格式便于后续处理

## 运行效果

```
======================================================================
                    智能新闻爬虫系统
                  Universal News Crawler
======================================================================
开始时间: 2025-06-30 14:30:00

🔍 正在检测可用的新闻网站...

==================================================
网站检测结果:
==================================================
✅ 网易财经       - 网站结构检测通过
   └─ 网站标题: 网易财经-有态度的财经门户...
✅ 新浪财经       - 网站结构检测通过
   └─ 网站标题: 新浪财经_新浪网...
⚠️ 腾讯财经       - 找到标题但未找到有效链接
   └─ 网站标题: 腾讯财经_腾讯网...
❌ 央视网财经     - 网站无法访问
❌ 人民网财经     - 网站无法访问

✅ 发现 2 个可用网站

请选择要爬取的新闻网站:
0. 自动选择最佳网站
1. 网易财经
2. 新浪财经

请输入选择 (0-2): 0
✅ 自动选择: 网易财经

==================================================
开始爬取: 网易财经
网站地址: https://money.163.com/
==================================================
✅ 爬虫初始化完成
✅ 数据管理器初始化完成

🚀 开始爬取 网易财经 新闻...
```

## 数据格式

### JSON 格式

```json
[
  {
    "title": "新闻标题",
    "url": "新闻链接",
    "summary": "新闻摘要",
    "crawl_time": "2025-06-30 12:00:00"
  }
]
```

### CSV 格式

```csv
title,url,summary,crawl_time
新闻标题,新闻链接,新闻摘要,2025-06-30 12:00:00
```

## 注意事项

1. **遵守 robots.txt**: 请在使用前检查目标网站的 robots.txt 文件
2. **适度爬取**: 避免过于频繁的请求，以免给服务器造成压力
3. **法律合规**: 仅用于学习和研究目的，不得用于商业用途
4. **网站变化**: 网站结构可能会发生变化，需要相应更新选择器

## 故障排除

### 常见问题

1. **无法获取新闻**:

   - 检查网络连接
   - 确认网站是否可访问
   - 查看日志文件获取详细错误信息

2. **数据保存失败**:

   - 检查 data 目录权限
   - 确认磁盘空间充足
   - 检查文件是否被其他程序占用

3. **依赖包安装失败**:
   - 使用 pip 更新到最新版本
   - 考虑使用清华源等国内镜像

## 更新日志

### v1.0.0 (2025-06-30)

- 初始版本发布
- 实现基本的新闻爬取功能
- 支持多种数据保存格式
- 添加完整的错误处理机制

## 许可证

本项目仅供学习和研究使用，请遵守相关法律法规。

## 作者

GitHub Copilot

## 反馈

如有问题或建议，请提交 Issue 或 Pull Request。
